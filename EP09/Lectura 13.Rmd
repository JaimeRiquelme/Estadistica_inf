---
title: "Lectura 13"
author: "Jaime Riquelme"
date: "2024-11-24"
output: pdf_document
---

# Configuración Inicial

```{r}
#Cargamos el conjunto de daots mtcars
data(mtcars)
```
#Correlacion

Verificamos la correlacion entre la variable potencia del motor con volumen util de los cilindros del motor o rendimiento del vehiculo.

```{r}
library(dplyr)

#Filtramos los datos
mtcars_filter <- mtcars %>% filter(mtcars$wt >= 2 & mtcars$wt <= 5) %>% select(hp, disp, mpg)

potencia <- mtcars_filter$hp
volumen <- mtcars_filter$disp
rendimiento <- mtcars_filter$mpg

#Creamos el grafico de dispersion

plot(volumen, potencia, xlab = "Potencia", ylab = "Volumen", main = "Potencia vs Volumen")
media_volumen <- mean(volumen)
sd_volumen <- sd(volumen)

cat("La media del volumen es: ", media_volumen, "\n")
cat("La desviacion estandar del volumen es: ", sd_volumen, "\n")

#Creamos el grafico de dispersion

plot(rendimiento, potencia, xlab = "Potencia", ylab = "Rendimiento", main = "Potencia vs Rendimiento")
media_rendimiento <- mean(rendimiento)
sd_rendimiento <- sd(rendimiento)

cat("La media del rendimiento es: ", media_rendimiento, "\n")
cat("La desviacion estandar del rendimiento es: ", sd_rendimiento, "\n")


```
En R podemos calcular la correlacion entre las dos variables usando la funcion cor(x,y)

```{r}
#Calculamos la correlacion entre potencia y volumen

correlacion_potencia_volumen <- cor(potencia, volumen)

cat("La correlacion entre potencia y volumen es: ", correlacion_potencia_volumen, "\n")

#Calculamos la correlacion entre potencia y rendimiento

correlacion_potencia_rendimiento <- cor(potencia, rendimiento)

cat("La correlacion entre potencia y rendimiento es: ", correlacion_potencia_rendimiento, "\n")
```
A su vez, si queremos calcular la correlacion entre todas las variables de un conjunto de datos, podemos usar la funcion cor() de la siguiente manera:

```{r}
correlacion_total <- cor(mtcars)

print(correlacion_total)
```
#Regresión lineal mediante minimos cuadrados

Formula:

$$ min \sum_{i=1}^{n} e_i^2 $$

Para aplicar este metodo se deben cumplir las siguientes condiciones:

1.- Las variables presentan una distribucion condicional bivariante, por lo que pra cunmmplir valor fijo de X, los valores de Y se distribuyyen nomralmente con una varianza constante.
2.- La relacion entre la variable X y las medias de la variable Y es lineal.
3.- Las observaciones de la muestra son inddependientes entre si. Esto significa ue no se puede usar regresion lineal cons eries de tiempo.

Si estas no se cumplem el metodo de minimos cuadrados pueden generar modelos compeltamente invalidos si nos e cumplen estas condiciones.

R nos permite calcular la regresion lineal mediante minimos cuadrados usando la funcion lm(formula,data) donde:

- formula: <variable respuesta>~<variable predictora>
- data: matriz de datos

variable de respuesta : variable dependiente
variable predictora: variable independiente

Ejemplo:

```{r}
library(dplyr)
library(ggpubr)
library(ggplot2)

#Filtramos los datos
mtcars_filter <- mtcars %>% filter(mtcars$wt >= 2 & mtcars$wt <= 5) 

#Ajustamos modelo con R

modelo <- lm(hp ~ disp, data = mtcars_filter)

print(summary(modelo))

#Graficamos los datos y el modelo obtenido

g1 <- ggscatter(mtcars_filter, x = "disp", y = "hp", 
                color = "steelblue", fill = "steelblue",
                ylab = "Potencia [hp]")
g1 <- g1 + geom_abline(intercept = coef(modelo)[1],
                       slope = coef(modelo)[2],
                       color = "red")
g1 <- g1 + xlab(bquote("Volumen útil de los cilindros" ~ group("[" , "in"^-3, "]")))

# Definir valores del predictor para vehículos no incluidos en el conjunto mtcars
disp <- c(169.694, 230.214, 79.005, 94.085, 343.085,
          136.073, 357.305, 288.842, 223.128, 129.217,
          146.432, 193.474, 376.874, 202.566, 114.928)

# Usar el modelo para predecir el rendimiento de estos modelos
potencia_est <- predict(modelo, data.frame(disp))

# Graficar los valores predichos
nuevos <- data.frame(disp, hp = potencia_est)
g2 <- ggscatter(nuevos, x = "disp", y = "hp",
                color = "purple", fill = "purple",
                ylab = "Potencia [hp]")
g2 <- g2 + xlab(bquote("Volumen útil de los cilindros" ~ group("[" , "in"^-3, "]")))

# Unir los gráficos en uno solo
g1 <- ggpar(g1, xlim = c(75, 405), ylim = c(60, 340))
g2 <- ggpar(g2, xlim = c(75, 405), ylim = c(60, 340))
g <- ggarrange(g1, g2,
               labels = c("Modelo", "Predicciones"),
               hjust = c(-1.2, -0.7))
print(g)

```

#Uso del modelo
  
Una vez que hemos ajustado el modelo, podemos usarlo para predecir valores de la variable dependiente para valores de la variable independiente que no estan en el conjunto de datos original.

En R tenemos la siguiente funcion para ello: 

predict(object, newdata) donde:

object: el modelo a emplear
newdata: Una matriz de datos donde exista una columna con el nombre del predictor usado en la formula del modelo, con los nuevos valores para los que se desea efectuar la prediccion.

Ejemplo:
Supongamos que queremos predecir que el motor del año 1974 con una cilindrada de 4 litros, es decir, disp = 244.095. para ello basta con reemplazar el valor del predictor en el modelo:

$$ \hat{h}_p = 34,523 + 0,507 * 244,095 = 158,279 $$
```{r}
disp_nuevo <- 244.095
potencia_est <- predict(modelo, data.frame(disp = disp_nuevo))

cat("La potencia estimada para un motor con una cilindrada de 244.095 in^3 es: ", potencia_est, "\n")

```

# Regresion lineal con un predictor categorico

Para ajustar un modelo de regresion lineal con un predictor categorico, se debe convertir la variable categorica en una variable dummy, es decir, una variable binaria que toma el valor de 1 si la categoria se cumple y 0 en caso contrario.

rara vez se hace manualmente, ya que las funciones en R lo realizan automaticamente.

El conjunto de datos mtcars cuenta con un par de variables indicadoras, la transmision am y la forma del mortor vs, de las dos la forma del motor tiene una correlacion mas fuerte con la potencia del motor, por eso que la usaremos como ejmplo para la creacion de un modelo de regresion lineal.

```{r}
library(ggpubr)

# Obtener los datos.
datos <- mtcars |> filter(wt > 2 & wt < 5)

# Verificar correlación.
print(cor(datos[, c("hp", "am", "vs")]))

# Ajustar modelo con R.
modelo_vs <- lm(hp ~ vs, data = datos)
print(summary(modelo_vs))

# Graficar el modelo.
g1 <- ggscatter(datos, x = "vs", y = "hp",
                color = "steelblue", fill = "steelblue",
                xlab = "Forma del motor", ylab = "Potencia [hp]",
                xticks.by = 1)
g1 <- g1 + geom_abline(intercept = coef(modelo_vs)[1],
                       slope = coef(modelo_vs)[2],
                       color = "red")
print(g1)

# Graficar residuos.
residuos <- modelo_vs[["residuals"]]
datos <- cbind(datos, residuos)

g2 <- ggscatter(datos, x = "vs", y = "residuos",
                color = "steelblue", fill = "steelblue",
                xlab = "Forma del motor", ylab = "Residuos [hp]",
                xticks.by = 1)
g2 <- g2 + geom_hline(yintercept = 0, color = "red")
print(g2)

# Unir los gráficos en uno solo
g <- ggarrange(g1, g2,
               labels = c("Modelo", "Residuos"),
               hjust = c(-2.5, -2.0))
print(g)

```
El análisis muestra que existe una relación significativa entre la forma del motor y su potencia: los motores en V tienden a ser más potentes, con una diferencia promedio de 86.03 hp más que los motores en línea. Sin embargo, el modelo solo explica el 41.44% de la variabilidad en la potencia, lo que sugiere que, aunque la forma del motor es un predictor importante, existen otros factores relevantes que no se están considerando y que influyen en la potencia del motor.

# Distribucion e independencia

Para que los modelos de regresion lineal sean validos, es necesario que los residuos sigan una distribucion normal y que sean independientes entre si.

en general cuando las condiciones se cumplen se observan caracteristicas en el grafico de los residuos: 

1.- se distribuyen aleatoriamente en torno a la liena del valor cero.
2.- forman una ""banda horizontal"" en torno a la linea del valor cero.
3. no hay residuos que se alejen del patron que forman los demás
4.- no forman un patron reconociible.

```{r}
library(car)
library(dplyr)
library(ggpubr)

# Cargar y filtrar los datos. Se usan los datos de mtcars pero solo aquellos con peso entre 2 y 5.
datos <- mtcars |> filter(wt > 2 & wt < 5)

# Ajustar modelo con R. Se ajusta un modelo de regresión lineal simple donde el rendimiento (hp) 
# se predice en función del desplazamiento del motor (disp).
modelo <- lm(hp ~ disp, data = datos)

# Desplegar gráficos de residuos y mostrar pruebas de curvatura.
# La función `residualPlots()` permite visualizar la relación entre los residuos y las variables para detectar curvaturas.
# Se especifica que se usen residuos estandarizados y se destacan las posibles curvas en rojo.
cat("Pruebas de curvatura:\n")
residualPlots(modelo, type = "rstandard",
              id = list(method = "r", n = 3, cex = 0.7, location = "lr"),
              col = "steelblue", pch = 20, col.quad = "red")

# Verificar independencia de los residuos
# La función `durbinWatsonTest()` verifica la independencia de los residuos, importante para validar la regresión.
# El valor del estadístico Durbin-Watson indica si hay autocorrelación en los residuos.
set.seed(19)
db <- durbinWatsonTest(modelo)
cat("\nPrueba de independencia:\n")
print(db)

# Desplegar gráficos marginales.
# La función `marginalModelPlots()` grafica los predictores frente a los residuos para identificar patrones.
# Esto ayuda a verificar si la relación entre las variables es realmente lineal.
marginalModelPlots(modelo, sd = TRUE,
                   id = list(method = "r", n = 3, cex = 0.7, location = "lr"),
                   col = "steelblue", pch = 20, col.line = c("steelblue", "red"))

# Prueba de la varianza del error no constante (homocedasticidad).
# La función `ncvTest()` realiza la prueba de homocedasticidad (Breusch-Pagan), 
# verificando si la varianza de los residuos es constante.
cat("\nPrueba de homocedasticidad:\n")
print(ncvTest(modelo))

# Desplegar gráficos de influencia.
# La función `influencePlot()` grafica los puntos de datos para identificar observaciones que podrían ser influyentes.
# Los casos influyentes pueden afectar significativamente la estimación de los parámetros del modelo.
casos_influyentes <- influencePlot(modelo, id = list(cex = 0.7))
cat("\nCasos que podrían ser influyentes:\n")
print(casos_influyentes)


```

# Influencia de los Valores Atípicos

Los valores atípicos pueden ser síntomas del incumplimiento de las condiciones para usar RLS, o que esté influenciada fuertemente por unos cuantos valores atípicos, por lo que el modelo no se generaliza bien para la población.

Cuando un valor atípico ejerce un desplazamiento de la línea de regresión basada en la nube principal de puntos, se le llama una **Observación o un punto influyente**.

Un valor relacionado a qué tan lejos se encuentra un valor x_i respecto a la media muestral puede utilizarse como una medida del potencial de x_i para influir en el ajuste. Esta medida se reconoce como **apalancamiento** o **leverage**, ya que parece tirar la línea hacia ellos. Se conoce como valor hat

para el i-esimo valor del predictor se calcula mediante la ecuacion : 

$$ h_{ii} = \frac{1}{n} + \frac{(x_i - \bar{x})^2}{\sum_{j=1}^{n} (x_j - \bar{x})^2}$$
Donde:

n es el numero de observaciones
x_i, x_j son respectivamente el i-esimo y j-esimo valor del predictor
x_bar es la media de los valores del predictor*

Como regla general lass observaciones con valores de apalancamiento igual o mayores a 2 veces el valor promedio que siempre corresponde a 2/n para la rls, son casos que pdorain ser influyentes pero no siempre indica un problema.

En R podemos calcular el apalancamiento de cada observacion usando la funcion hatvalues(modelo) donde modelo es el modelo de regresion lineal ajustado.

```{r}
#Prueba de apalancamiento

# Calcular el apalancamiento de cada observación.

apalancamiento <- hatvalues(modelo)

# Calcular el promedio del apalancamiento.

promedio_apalancamiento <- 2 / nrow(datos)

# Identificar observaciones con apalancamiento mayor al doble del promedio.

observaciones_influyentes <- which(apalancamiento > 2 * promedio_apalancamiento)

cat("Observaciones influyentes:\n")

print(observaciones_influyentes)
print(apalancamiento)

```

```{r}
# Cargar el conjunto de datos mtcars
data(mtcars)

# Filtrar los datos según las condiciones
library(dplyr)
mtcars_filter <- mtcars %>% filter(mtcars$wt >= 2 & mtcars$wt <= 5)

# Definir variables necesarias
volumen <- mtcars_filter$disp
n <- length(volumen)

# Función para calcular el apalancamiento manualmente
calcular_apalancamiento_manual <- function(x) {
  x_bar <- mean(x)
  numerador <- (x - x_bar)^2
  denominador <- sum((x - x_bar)^2)
  apalancamiento <- (1 / n) + (numerador / denominador)
  return(apalancamiento)
}

# Calcular el apalancamiento usando la función creada
apalancamiento_manual <- calcular_apalancamiento_manual(volumen)

# Calcular el apalancamiento usando la función hatvalues() en un modelo ajustado
modelo <- lm(hp ~ disp, data = mtcars_filter)
apalancamiento_hatvalues <- hatvalues(modelo)

# Comparar ambos métodos
cat("Apalancamiento calculado manualmente:\n")
print(apalancamiento_manual)

cat("\nApalancamiento calculado con hatvalues():\n")
print(apalancamiento_hatvalues)

# Verificar si los valores coinciden
diferencias <- apalancamiento_manual - apalancamiento_hatvalues
cat("\nDiferencias entre el apalancamiento manual y hatvalues():\n")
print(diferencias)

# Mostrar si existen diferencias significativas
if (all(abs(diferencias) < 1e-10)) {
  cat("\nLos valores de apalancamiento calculados manualmente y con hatvalues() son iguales.\n")
} else {
  cat("\nExisten diferencias entre los valores calculados manualmente y con hatvalues().\n")
}

```

# Calidad predictiva del modelo de RLS

Esto servirá para verificar si las predicciones que podemos obtener con el modelo son de buena calidad.

## Error de un modelo RLS

la calidad del modelo puede asociarse a los errores $$ e_i $$ que comete en las estimaciones  y_i de un conjunto de observaciones, estableciendo una relacion y_i = y_i + e_i

pero usando un modelo más general:

y_1 = mean(y_1) + e_1

En este capitulo el errro que se comete en la estimacion de y_i se le conoce como **error residual** r_i.

Podemos usar el error cuadratico medio como una metrica de la calidad de un modelo de RLS

Para el ejemplo anterior, se consigue un MSE = 1.914.377, Equivalente a un RMSE = 43,753, En principio es un resultado aceptable, ya que la variable de salida tiene un rango que va de los 62 a los 335 caballos de fuerza.


## Generalización

Diremos que un modelo es generalizable si para un conjunto de datos nuevo consigue predicciones con una calidad similar a la que consigue con los datos usados en su construcción.

La estrategia más frecuente es la validación cruzada, donde se separa en dos fragmentos:

- Conjunto de entrenamiento: suele contener entre el 80% y 90% de las observaciones, escogidas de manera aleatoria y se emplea para ajustar la recta con el método de mínimos cuadrados.

- Conjunto de prueba: contiene el 10% a 30% restante de la muestra, y se usa para evaluar el modelo con datos nuevos.

La idea del modelo es evaluar cómo se comporta con datos que no ha visto previamente, en comparación al comportamiento con el conjunto de entrenamiento.

ejemplo en R:

```{r}
datos <- mtcars_filter
n <- nrow(datos)

#Creamos el conjunto de entrenamiento y prueba

set.seed(101)

n_entrenamiento <- floor(0.8 * n)
i_entrenamiento <- sample.int(n = n, size = n_entrenamiento, replace = FALSE)

entrenamiento <- datos[i_entrenamiento, ]
prueba <- datos[-i_entrenamiento, ]

#Ajustamos y mostramos el modelo con el conjunto de entrenamiento

modelo <- lm(hp ~ disp, data = entrenamiento)

print(summary(modelo))

#Calculamos el arror cuadrado promedio para el conjunto de entrenamiento

rmse_entrenamiento <- sqrt(mean(resid(modelo)^2))
cat("RMSE para el conjunto de entrenamiento: ", rmse_entrenamiento, "\n")

#Hacemos las predicciones para el conjunto de prueba

predicciones <- predict(modelo,prueba)

#Calculamos error cuadrado promedio para el conjunto de prueba

error <- prueba[["hp"]] - predicciones
rmse_prueba <- sqrt(mean(error^2))
cat("RMSE para el conjunto de prueba: ", rmse_prueba, "\n")
```

Pero puede ocurrir que por situaciones aleatorias, el conjunto de prueba quede con observaciones que no representan adecuadamente la muestra de datos original, llevando a una estimación equivocada. Es por eso que una manera de mejorar es generalizar la estrategia anterior y usar validación cruzada de k pliegues.

Obtenemos las estimaciones de error de la siguiente manera:

1. Para cada uno de los k subconjuntos:
   a) Tomar uno de los k subconjuntos del conjunto de entrenamiento y reservarlo como conjunto de prueba.
   b) Ajustar la recta de mínimos cuadrados usando para ello los datos combinados de los k-1 subconjuntos restantes.
   c) Estimar el error cuadrático medio usando para ello el conjunto de prueba.

2. Estimar el error cuadrático medio, correspondiente a la media de los k MSE obtenidos en el paso 1.

En R podemos hacer la contruccion del modelo de RLS usando 5-CV con la funcion train(formula, method = "lm", trControl = trainControl(metrod = "cv", number = 5), data = datos) donde:

formula = formula que se emplea en las llamadas internas a la funcion lm()
number: cantidad de pliegues (k).

```{r}
library(caret)
library(dplyr)

#Datos
datos <- mtcars_filter
n <- nrow(datos)

#Ajustamos y mostramos el modelo usando validacion cruzada de 5 pliegues.

set.seed(111)

entrenamiento <- train(hp ~ disp , data = datos, method = "lm", trControl = trainControl(method = "cv", number = 5))

modelo <- entrenamiento[["finalModel"]]

print(summary(modelo))

#Mostramos los resultados de cada pliegue
cat("Resultados de cada pliegue:\n")
print(entrenamiento[["resample"]])

#Mostramos el resultado estimado para el modelo

cat("Error estimado para el modelo \n")
print(entrenamiento[["results"]])

```

los resultados obtenidos son inquietantes por que tenemos una sd de 21,560, ya que para el pliegue1 el error fue de RMSE =15,162, mientras que para el 3 alcanzo un RMSE = 71,254, entonces sugiere que existe una o más observaciones influyentes en la muestra.

para casos de muestras pequeñas, se recomienda usar validacion cruzada usando tantos pliegues como observaciones, en otras palabras de hacer n modelos distintos, dejando una observacion distinta de la muestra de datos sin ser considerara.

En r podemos hacer el modelo de RLS ejemplo usando LOOCV

```{r}

library(caret)
library(dplyr)

#Datos
datos <- mtcars_filter
n <- nrow(datos)

#Ajustar y mostrar el modelo usando validacion cruzada de 5 pliegues.
set.seed(111)

entrenamiento <- train(hp ~ disp, data = datos, method = "lm", trControl = trainControl(method = "LOOCV"))

modelo <- entrenamiento[["finalModel"]]

print(summary(modelo))

#Mostrar los errores.

cat("Resultados de cada pliegue:\n")
print(entrenamiento[["pred"]])

#Mostrar el resultado estimado para el modelo
cat("Error estimado para el modelo:\n")
print(entrenamiento[["results"]])

```