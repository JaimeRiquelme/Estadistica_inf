#librerias
library(dplyr)
library(ggplot2)
library(car)
library(ggpubr)
library(tidyr)
#Leemos los datos a utilizar
datos <- read.csv2("EP09 Datos.csv")
#Mostramos los primeros datos
head(datos)
# Definimos la semilla para realizar las preguntas solicitadas.
set.seed(8603)
# 2.- Seleccionar una muestra aleatoria de 100 mujeres (si la semilla es un número par) o 100 hombres (si la semilla es impar), y separar 70 casos para trabajar en la construcción de modelos y 30 para su evaluación en datos no vistos.
#Seleccionamos una muestra aleatoria de 100 hombres, dado que la semilla es impar.
#Seleccionamos los hombres
datos_randoms_hombres <- datos %>% filter(Gender == 1) %>% sample_n(100)
#Separamos 70 casos para trabajar en la construcción de modelos y 30 para su evaluación en datos no vistos.
#Creamos un vector con los índices de los datos
indices <- 1:100
#Seleccionamos los primeros 70 datos para trabajar en la construcción de modelos
datos_entrenamiento <- datos_randoms_hombres[indices[1:70],]
#Seleccionamos los últimos 30 datos para evaluar en datos no vistos
datos_prueba <- datos_randoms_hombres[indices[71:100],]
#3.- Seleccionar de forma aleatoria ocho posibles variables predictoras.
#Obtenemos los nombres de las columnas de nuestros datos y eliminamos la columna Weight y Height
nombres_columnas <- colnames(datos) %>% setdiff(c("Weight", "Height"))
#Seleccionamos de forma aleatoria ocho posibles variables predictoras.
Col_seleccionadas <- sample(nombres_columnas, 8)
print(Col_seleccionadas)
#Lista con las variables restantes para elegir un predictor
nombres_columnas_restantes <- nombres_columnas %>% setdiff(Col_seleccionadas)
print(nombres_columnas_restantes)
Col_seleccionadas <- c(Col_seleccionadas, "Weight", "Thigh.Girth")
# Es la tabla que contiene solo nuestras 8 variables aleatorias predictorias
tabla_va <- datos_entrenamiento %>% select(all_of(Col_seleccionadas))
print(Col_seleccionadas)
#Generamos al modelo inicial con el predictor elegido en el paso anterior
modelo_inicial <- lm(Weight ~ Thigh.Girth, data = datos_entrenamiento)
#Mostramos el modelo
print(summary(modelo_inicial))
#Mostramos el modelo en un gráfico
grafico_modelo_inicial <- ggplot(datos_entrenamiento, aes(x = Thigh.Girth, y = Weight)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Modelo de regresión lineal simple", x = "Grosor del muslo", y = "Peso")
print(grafico_modelo_inicial)
# Análisis de residuos y casos influyentes
# Identificamos residuos estandarizados fuera del intervalo [-1.96, 1.96]
residuos_estandarizados <- rstandard(modelo_inicial)
casos_atipicos <- which(abs(residuos_estandarizados) > 1.96)
cat("Residuos estandarizados fuera del 95% esperado:\n")
print(casos_atipicos)
# Análisis de valores influyentes usando la distancia de Cook
# Usamos el umbral 4/n como es común en la práctica
dist_cook <- cooks.distance(modelo_inicial)
n <- nrow(datos_entrenamiento)
casos_influyentes <- which(dist_cook > 4/n)
cat("\nCasos influyentes (distancia de Cook > 4/n):\n")
print(casos_influyentes)
# Análisis de apalancamiento (leverage)
# Calculamos el valor de corte 2(p+1)/n, donde p es el número de predictores
p <- 1  # un solo predictor
h <- hatvalues(modelo_inicial)
apalancamiento_corte <- 2 * (p + 1) / n
casos_apalancamiento <- which(h > apalancamiento_corte)
cat("\nCasos con alto apalancamiento (h > 2(p+1)/n):\n")
print(casos_apalancamiento)
# Gráficos de diagnóstico
par(mfrow=c(2,2))
plot(modelo_inicial)
#Ajustamos a nuestro modelo del paso 5.
completo <- lm(Weight ~ ., data = tabla_va)
print(completo)
opt <- options(digits = 2, width = 52)
modelo <- step(modelo_inicial, scope = list(lower = modelo_inicial, upper = completo),
direction = "both",
k = log(nrow(tabla_va)),
test = "F",
trace = 1)
options(digits = opt[[1]], width = opt[[2]])
#Mostramos los coeficientes del modelo conseguido
cat("\nModelo obtenido:\n")
print(modelo[["coefficients"]])
# comprobar colinealidad
# primero VIF
cat("VIF: \n")
print(vif(modelo))
# Segundo las tolerancias
cat("Tolerancias:\n")
print(1 / vif(modelo))
# Comprobar la independencia de residuos, no autocorrelación entre residuos
cat(" \nPrueba de Durbin-Watson para autocorrelaciones ")
# Con hipótesis nula = los residuos son independientes  / no hay autocorrelación
#Hipótesis alternativa = Los residuos no son independientes.
print( durbinWatsonTest(modelo))
# Comprobamos normalidad de los residuos
#con Hipótesis nula = Los datos provienen de una distribución normal
#Hipótesis alternativa = Los datos no siguen una distribución normal.
cat("\ nPrueba de normalidad para los residuos :\n")
print(shapiro.test( modelo$residuals))
# Comprobar homocedasticidad de los residuos
cat("Prueba de homocedasticidad para los residuos:\n")
print(ncvTest(modelo))
# Comprobar variabilidad de los predictores del modelo
cat("\nPrueba de variabilidad de los predictores:\n")
print(summary(modelo))
# Comprobar la linealidad con la variable de respuesta del modelo
cat("\nPrueba de linealidad de la variable respuesta:\n")
residualPlots(modelo,
type = "rstandard",
id = list(method = "r", n = 3, cex =0.7, location = "lr"),
col = "red", pch = 20, col.quad = "purple")
# Comprobar las estimaciones de los coeficientes del modelo
cat("\nPrueba de coeficientes del modelo:\n")
influencePlot(modelo)
# 8.- Evaluar el poder predictivo del modelo con los datos no utilizados para construirlo.
# Calculamos el RMSE para el conjunto de entrenamiento
rmse_entrenamiento <- sqrt(mean(resid(modelo)^2))
# Hacemos predicciones en el conjunto de prueba
predicciones <- predict(modelo, newdata = datos_prueba)
residuos_prueba <- datos_prueba$Weight - predicciones
rmse_prueba <- sqrt(mean(residuos_prueba^2))
# Calculamos el porcentaje de cambio en el error
pct_cambio <- ((rmse_prueba - rmse_entrenamiento) / rmse_entrenamiento) * 100
# Calculamos R² para los datos de prueba
r2_prueba <- 1 - sum((datos_prueba$Weight - predicciones)^2) /
sum((datos_prueba$Weight - mean(datos_prueba$Weight))^2)
# Mostramos los resultados
cat("Rendimiento del modelo:\n")
cat("RMSE para el conjunto de entrenamiento:", round(rmse_entrenamiento, 3), "\n")
cat("RMSE para el conjunto de prueba:", round(rmse_prueba, 3), "\n")
cat("Cambio en el error:", round(pct_cambio, 2), "%\n")
cat("R² en datos de prueba:", round(r2_prueba, 4), "\n")
# Crear un gráfico de valores reales vs predichos
ggplot(data = data.frame(reales = datos_prueba$Weight, predichos = predicciones),
aes(x = reales, y = predichos)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
labs(x = "Valores reales", y = "Valores predichos",
title = "Comparación de valores reales vs predichos en datos de prueba") +
theme_minimal()
# Librerías
library(dplyr)
library(ggplot2)
library(car)
library(ggpubr)
library(tidyr)
# Leemos los datos a utilizar
datos <- read.csv2("EP09 Datos.csv")
# Mostramos los primeros datos
head(datos)
# Definimos la semilla para realizar las preguntas solicitadas.
set.seed(8603)
# Seleccionamos una muestra aleatoria de 100 hombres, dado que la semilla es impar.
# Seleccionamos los hombres
datos_randoms_hombres <- datos %>% filter(Gender == 1) %>% sample_n(100)
# Separamos 70 casos para trabajar en la construcción de modelos y 30 para su evaluación en datos no vistos.
# Creamos un vector con los índices de los datos
indices <- 1:100
# Seleccionamos los primeros 70 datos para trabajar en la construcción de modelos
datos_entrenamiento <- datos_randoms_hombres[indices[1:70],]
# Seleccionamos los últimos 30 datos para evaluar en datos no vistos
datos_prueba <- datos_randoms_hombres[indices[71:100],]
# Obtenemos los nombres de las columnas de nuestros datos y eliminamos la columna Weight y Height
nombres_columnas <- colnames(datos) %>% setdiff(c("Weight", "Height"))
# Seleccionamos de forma aleatoria ocho posibles variables predictoras.
Col_seleccionadas <- sample(nombres_columnas, 8)
print(Col_seleccionadas)
# Lista con las variables restantes para elegir un predictor
nombres_columnas_restantes <- nombres_columnas %>% setdiff(Col_seleccionadas)
print(nombres_columnas_restantes)
Col_seleccionadas <- c(Col_seleccionadas, "Weight", "Thigh.Girth")
# Es la tabla que contiene solo nuestras 8 variables aleatorias predictorias
tabla_va <- datos_entrenamiento %>% select(all_of(Col_seleccionadas))
print(Col_seleccionadas)
# Generamos el modelo inicial con el predictor elegido en el paso anterior
modelo_inicial <- lm(Weight ~ Thigh.Girth, data = datos_entrenamiento)
# Mostramos el modelo
print(summary(modelo_inicial))
# Mostramos el modelo en un gráfico
grafico_modelo_inicial <- ggplot(datos_entrenamiento, aes(x = Thigh.Girth, y = Weight)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Modelo de regresión lineal simple", x = "Grosor del muslo", y = "Peso")
print(grafico_modelo_inicial)
# Análisis de residuos y casos influyentes
# Identificamos residuos estandarizados fuera del intervalo [-1.96, 1.96]
residuos_estandarizados <- rstandard(modelo_inicial)
casos_atipicos <- which(abs(residuos_estandarizados) > 1.96)
cat("Residuos estandarizados fuera del 95% esperado:\n")
print(casos_atipicos)
# Análisis de valores influyentes usando la distancia de Cook
# Usamos el umbral 4/n como es común en la práctica
dist_cook <- cooks.distance(modelo_inicial)
n <- nrow(datos_entrenamiento)
casos_influyentes <- which(dist_cook > 4/n)
cat("\nCasos influyentes (distancia de Cook > 4/n):\n")
print(casos_influyentes)
# Análisis de apalancamiento (leverage)
# Calculamos el valor de corte 2(p+1)/n, donde p es el número de predictores
p <- 1  # un solo predictor
h <- hatvalues(modelo_inicial)
apalancamiento_corte <- 2 * (p + 1) / n
casos_apalancamiento <- which(h > apalancamiento_corte)
cat("\nCasos con alto apalancamiento (h > 2(p+1)/n):\n")
print(casos_apalancamiento)
# Gráficos de diagnóstico
par(mfrow=c(2,2))
plot(modelo_inicial)
# Ajustamos a nuestro modelo del paso 5.
completo <- lm(Weight ~ ., data = tabla_va)
print(completo)
opt <- options(digits = 2, width = 52)
modelo <- step(modelo_inicial, scope = list(lower = modelo_inicial, upper = completo),
direction = "both",
k = log(nrow(tabla_va)),
test = "F",
trace = 1)
options(digits = opt[[1]], width = opt[[2]])
# Mostramos los coeficientes del modelo conseguido
cat("\nModelo obtenido:\n")
print(modelo[["coefficients"]])
# Comprobar colinealidad
# Primero VIF
cat("VIF: \n")
print(vif(modelo))
# Segundo las tolerancias
cat("Tolerancias:\n")
print(1 / vif(modelo))
# Comprobar la independencia de residuos, no autocorrelación entre residuos
cat("\nPrueba de Durbin-Watson para autocorrelaciones\n")
# Con hipótesis nula = los residuos son independientes / no hay autocorrelación
# Hipótesis alternativa = Los residuos no son independientes.
print(durbinWatsonTest(modelo))
# Comprobar normalidad de los residuos
# Con hipótesis nula = Los datos provienen de una distribución normal
# Hipótesis alternativa = Los datos no siguen una distribución normal.
cat("\nPrueba de normalidad para los residuos:\n")
print(shapiro.test(modelo$residuals))
# Comprobar homocedasticidad de los residuos
cat("Prueba de homocedasticidad para los residuos:\n")
print(ncvTest(modelo))
# Comprobar variabilidad de los predictores del modelo
cat("\nPrueba de variabilidad de los predictores:\n")
print(summary(modelo))
# Comprobar la linealidad con la variable de respuesta del modelo
cat("\nPrueba de linealidad de la variable respuesta:\n")
residualPlots(modelo,
type = "rstandard",
id = list(method = "r", n = 3, cex = 0.7, location = "lr"),
col = "red", pch = 20, col.quad = "purple")
# Comprobar las estimaciones de los coeficientes del modelo
cat("\nPrueba de coeficientes del modelo:\n")
influencePlot(modelo)
# Calculamos el RMSE para el conjunto de entrenamiento
rmse_entrenamiento <- sqrt(mean(resid(modelo)^2))
# Hacemos predicciones en el conjunto de prueba
predicciones <- predict(modelo, newdata = datos_prueba)
residuos_prueba <- datos_prueba$Weight - predicciones
rmse_prueba <- sqrt(mean(residuos_prueba^2))
# Calculamos el porcentaje de cambio en el error
pct_cambio <- ((rmse_prueba - rmse_entrenamiento) / rmse_entrenamiento) * 100
# Calculamos R2 para los datos de prueba
r2_prueba <- 1 - sum((datos_prueba$Weight - predicciones)^2) /
sum((datos_prueba$Weight - mean(datos_prueba$Weight))^2)
# Mostramos los resultados
cat("Rendimiento del modelo:\n")
cat("RMSE para el conjunto de entrenamiento:", round(rmse_entrenamiento, 3), "\n")
cat("RMSE para el conjunto de prueba:", round(rmse_prueba, 3), "\n")
cat("Cambio en el error:", round(pct_cambio, 2), "%\n")
cat("R² en datos de prueba:", round(r2_prueba, 4), "\n")
# Creamos el gráfico con los datos reales vs los datos predichos.
ggplot(data = data.frame(reales = datos_prueba$Weight, predichos = predicciones),
aes(x = reales, y = predichos)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
labs(x = "Valores reales", y = "Valores predichos",
title = "Comparación de valores reales vs predichos en datos de prueba") +
theme_minimal()
# Generamos el modelo inicial con el predictor elegido en el paso anterior
modelo_inicial <- lm(Weight ~ Thigh.Girth, data = datos_entrenamiento)
# Mostramos el modelo
print(summary(modelo_inicial))
# Mostramos el modelo en un gráfico
grafico_modelo_inicial <- ggplot(datos_entrenamiento, aes(x = Thigh.Girth, y = Weight)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Modelo de regresión lineal simple", x = "Grosor del muslo", y = "Peso")
# Mostramos el modelo
print(summary(modelo_inicial))
# Interpretación del modelo simple:
# El modelo de regresión lineal simple usando el grosor del muslo como predictor muestra:
# - Un R² ajustado de 0.6469, lo que significa que aproximadamente el 64.69% de la
#   variabilidad en el peso es explicada por el grosor del muslo.
# - El coeficiente de Thigh.Girth (2.1653) es estadísticamente significativo (p < 0.001)
#   e indica que por cada centímetro adicional de grosor del muslo, el peso aumenta en
#   promedio 2.17 kg, manteniendo todo lo demás constante.
# - El error estándar residual de 6.759 kg sugiere una precisión moderada en las predicciones.
# - La significancia global del modelo (F-statistic: 127.4, p < 2.2e-16) confirma que
#   el grosor del muslo es un predictor útil del peso corporal.
# Librerías
library(dplyr)
library(ggplot2)
library(car)
library(ggpubr)
library(tidyr)
# Leemos los datos a utilizar
datos <- read.csv2("EP09 Datos.csv")
# Mostramos los primeros datos
head(datos)
# Definimos la semilla para realizar las preguntas solicitadas.
set.seed(8603)
# Seleccionamos una muestra aleatoria de 100 hombres, dado que la semilla es impar.
# Seleccionamos los hombres
datos_randoms_hombres <- datos %>% filter(Gender == 1) %>% sample_n(100)
# Separamos 70 casos para trabajar en la construcción de modelos y 30 para su evaluación en datos no vistos.
# Creamos un vector con los índices de los datos
indices <- 1:100
# Seleccionamos los primeros 70 datos para trabajar en la construcción de modelos
datos_entrenamiento <- datos_randoms_hombres[indices[1:70],]
# Seleccionamos los últimos 30 datos para evaluar en datos no vistos
datos_prueba <- datos_randoms_hombres[indices[71:100],]
# Obtenemos los nombres de las columnas de nuestros datos y eliminamos la columna Weight y Height
nombres_columnas <- colnames(datos) %>% setdiff(c("Weight", "Height"))
# Seleccionamos de forma aleatoria ocho posibles variables predictoras.
Col_seleccionadas <- sample(nombres_columnas, 8)
print(Col_seleccionadas)
matriz <- cor(datos_entrenamiento)
cor_peso <- matriz[, c(1, which(colnames(matriz) == "Weight"))]
print(cor_peso)
# Lista con las variables restantes para elegir un predictor
nombres_columnas_restantes <- nombres_columnas %>% setdiff(Col_seleccionadas)
print(nombres_columnas_restantes)
Col_seleccionadas <- c(Col_seleccionadas, "Weight", "Hip.Girth")
# Es la tabla que contiene solo nuestras 8 variables aleatorias predictorias
tabla_va <- datos_entrenamiento %>% select(all_of(Col_seleccionadas))
print(Col_seleccionadas)
# Generamos el modelo inicial con el predictor elegido en el paso anterior
modelo_inicial <- lm(Weight ~ Hip.Girth, data = datos_entrenamiento)
# Mostramos el modelo
print(summary(modelo_inicial))
# Mostramos el modelo en un gráfico
grafico_modelo_inicial <- ggplot(datos_entrenamiento, aes(x = Hip.Girth, y = Weight)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Modelo de regresión lineal simple", x = "Grosor de la cadera", y = "Peso")
# Mostramos el modelo
print(summary(modelo_inicial))
# Análisis de residuos y casos influyentes
# Identificamos residuos estandarizados fuera del intervalo [-1.96, 1.96]
residuos_estandarizados <- rstandard(modelo_inicial)
casos_atipicos <- which(abs(residuos_estandarizados) > 1.96)
cat("Residuos estandarizados fuera del 95% esperado:\n")
print(casos_atipicos)
# Análisis de valores influyentes usando la distancia de Cook
# Usamos el umbral 4/n como es común en la práctica
dist_cook <- cooks.distance(modelo_inicial)
n <- nrow(datos_entrenamiento)
casos_influyentes <- which(dist_cook > 4/n)
cat("\nCasos influyentes (distancia de Cook > 4/n):\n")
print(casos_influyentes)
# Análisis de apalancamiento (leverage)
# Calculamos el valor de corte 2(p+1)/n, donde p es el número de predictores
p <- 1  # un solo predictor
h <- hatvalues(modelo_inicial)
apalancamiento_corte <- 2 * (p + 1) / n
casos_apalancamiento <- which(h > apalancamiento_corte)
cat("\nCasos con alto apalancamiento (h > 2(p+1)/n):\n")
print(casos_apalancamiento)
# Gráficos de diagnóstico
par(mfrow=c(2,2))
plot(modelo_inicial)
# Ajustamos a nuestro modelo del paso 5.
completo <- lm(Weight ~ ., data = tabla_va)
print(completo)
opt <- options(digits = 2, width = 52)
modelo <- step(modelo_inicial, scope = list(lower = modelo_inicial, upper = completo),
direction = "both",
k = log(nrow(tabla_va)),
test = "F",
trace = 1)
options(digits = opt[[1]], width = opt[[2]])
# Mostramos los coeficientes del modelo conseguido
cat("\nModelo obtenido:\n")
print(modelo[["coefficients"]])
# Comprobar colinealidad
# Primero VIF
cat("VIF: \n")
print(vif(modelo))
# Segundo las tolerancias
cat("Tolerancias:\n")
print(1 / vif(modelo))
# Comprobar la independencia de residuos, no autocorrelación entre residuos
cat("\nPrueba de Durbin-Watson para autocorrelaciones\n")
# Con hipótesis nula = los residuos son independientes / no hay autocorrelación
# Hipótesis alternativa = Los residuos no son independientes.
print(durbinWatsonTest(modelo))
# Comprobar normalidad de los residuos
# Con hipótesis nula = Los datos provienen de una distribución normal
# Hipótesis alternativa = Los datos no siguen una distribución normal.
cat("\nPrueba de normalidad para los residuos:\n")
print(shapiro.test(modelo$residuals))
# Comprobar homocedasticidad de los residuos
cat("Prueba de homocedasticidad para los residuos:\n")
print(ncvTest(modelo))
# Comprobar variabilidad de los predictores del modelo
cat("\nPrueba de variabilidad de los predictores:\n")
print(summary(modelo))
# Comprobar la linealidad con la variable de respuesta del modelo
cat("\nPrueba de linealidad de la variable respuesta:\n")
residualPlots(modelo,
type = "rstandard",
id = list(method = "r", n = 3, cex = 0.7, location = "lr"),
col = "red", pch = 20, col.quad = "purple")
# Comprobar las estimaciones de los coeficientes del modelo
cat("\nPrueba de coeficientes del modelo:\n")
influencePlot(modelo)
# Calculamos el RMSE para el conjunto de entrenamiento
rmse_entrenamiento <- sqrt(mean(resid(modelo)^2))
# Hacemos predicciones en el conjunto de prueba
predicciones <- predict(modelo, newdata = datos_prueba)
residuos_prueba <- datos_prueba$Weight - predicciones
rmse_prueba <- sqrt(mean(residuos_prueba^2))
# Calculamos el porcentaje de cambio en el error
pct_cambio <- ((rmse_prueba - rmse_entrenamiento) / rmse_entrenamiento) * 100
# Calculamos R2 para los datos de prueba
r2_prueba <- 1 - sum((datos_prueba$Weight - predicciones)^2) /
sum((datos_prueba$Weight - mean(datos_prueba$Weight))^2)
# Mostramos los resultados
cat("Rendimiento del modelo:\n")
cat("RMSE para el conjunto de entrenamiento:", round(rmse_entrenamiento, 3), "\n")
cat("RMSE para el conjunto de prueba:", round(rmse_prueba, 3), "\n")
cat("Cambio en el error:", round(pct_cambio, 2), "%\n")
cat("R² en datos de prueba:", round(r2_prueba, 4), "\n")
# Creamos el gráfico con los datos reales vs los datos predichos.
ggplot(data = data.frame(reales = datos_prueba$Weight, predichos = predicciones),
aes(x = reales, y = predichos)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
labs(x = "Valores reales", y = "Valores predichos",
title = "Comparación de valores reales vs predichos en datos de prueba") +
theme_minimal()
