---
title: "EP10"
author: "Grupo 8"
date: "2024-12-10"
output: pdf_document
---
Para este ejercicio usaremos los datos de medidas anatómicas recolectados por Heinz et al. (2003) que ya conocimos en el ejercicio práctico anterior (disponibles en el archivo "EP09 Datos.csv"). Como en este case se requiere de una variable dicotómica, vamos a realizar lo siguiente:

1.- El equipo crea la variable IMC (índice de masa corporal) como el peso de una persona (en kilogramos) dividida por el cuadrado de su estatura (en metros).
2.- Si bien esta variable se usa para clasificar a las personas en varias clases de estado nutricional (bajo peso, normal, sobrepeso, obesidad, obesidad mórbida), para efectos de este ejercicio, usaremos dos clases: sobrepeso (IMC ≥ 23,2) y no sobrepeso (IMC < 23,2).
3.- El equipo crea la variable dicotómica EN (estado nutricional) de acuerdo al valor de IMC de cada persona.
Ahora podemos construir un modelo de regresión logística para predecir la variable EN, de acuerdo con las siguientes instrucciones:

## 1.-Definir la semilla a utilizar, que corresponde a los últimos cuatro dígitos del RUN (sin considerar el dígito verificador) del integrante de mayor edad del equipo.

```{r}
#Realizamos la lectura de los datos.

datos <- read.csv2("EP09 Datos.csv")

#Definimos la semilla a utilizar

set.seed(6887)
```

## 2.-Seleccionar una muestra de 150 mujeres (si la semilla es un número par) o 150 hombres (si la semilla es impar), asegurando que la mitad tenga estado nutricional “sobrepeso” y la otra mitad “no sobrepeso” en cada caso. Dividir esta muestra en dos conjuntos: los datos de 100 personas (50 con EN “sobrepeso”) para utilizar en la construcción de los modelos (entramiento) y 50 personas (25 con EN “sobrepeso”) para poder evaluarlos.

```{r}
# Librerias a utilizar
library(caret) 
library(dplyr) 
library(ggpubr)
library(pROC)
library(car)  

#Primero creamos la variable IMC para cada persona
#Añadimos la nueva columna IMC a la tabla de datos usando mutate

# Convertimos la altura de centímetros a metros
datos <- datos %>% mutate(Height = Height / 100)

# Calculamos el IMC 
datos <- datos %>% mutate(IMC = Weight / (Height^2))

#Segundo creamos la variable EN para cada persona
datos <- datos %>% mutate(EN = ifelse(IMC >= 23.2, "sobrepeso", "no sobrepeso"))

#Seleccionamos la muestra de 150 hombres.
muestra_sobrepeso <- datos %>% filter(Gender == 1 & EN == "sobrepeso") %>% sample_n(75, replace = FALSE)
muestra_no_sobrepeso <- datos %>% filter(Gender == 1 & EN == "no sobrepeso") %>% sample_n(75, replace = FALSE)

#Seleccionamos 50 personas sobrepeso y 50 personas no sobrepeso para construir los modelos. 

muestra_sobrepeso_modelo <- muestra_sobrepeso[1:50,]
muestra_no_sobrepeso_modelo <- muestra_no_sobrepeso[1:50,]

#Seleccionamos 25 personas sobre peso y 25 personas no sobre peso para evaluar los modelos.

muestra_sobrepeso_evaluar <- muestra_sobrepeso[51:75,]
muestra_no_sobrepeso_evaluar <- muestra_no_sobrepeso[51:75,]

# Combinar los conjuntos de entrenamiento
muestra_entrenamiento <- bind_rows(muestra_sobrepeso_modelo, muestra_no_sobrepeso_modelo)

# Combinar los conjuntos de prueba
muestra_prueba <- bind_rows(muestra_sobrepeso_evaluar, muestra_no_sobrepeso_evaluar)


```

## 3.-Recordar las ocho posibles variables predictoras seleccionadas de forma aleatoria en el ejercicio anterior.
```{r}
#Aplicando filtro para obtener solo las 8 variables que obtuvimos aleatoriamente
# Guardar los nombres de las variables seleccionadas
nombres_variables <- c("Knees.diameter", "Gender", "Chest.Girth", 
                       "Ankle.Minimum.Girth", "Age", 
                       "Navel.Girth", "Hip.Girth", 
                       "Elbows.diameter")

# Seleccionar las variables deseadas
variables_seleccionadas <- subset(datos, select = c("Knees.diameter", "Gender", "Chest.Girth", 
                                                      "Ankle.Minimum.Girth", "Age", 
                                                      "Navel.Girth", "Hip.Girth", 
                                                      "Elbows.diameter"))


```

## 4.-Seleccionar, de las otras variables, una que el equipo considere que podría ser útil para predecir la clase EN, justificando bien esta selección (idealmente con literatura).
Siendo EN la variable dicotómica estado nutricional seleccionaremos la variables Waist Girth (que es la circunferencia de la cintura)
para predecir el estado nutricional ya que ayuda a evaluar la distribución de la grasa corporal y puede ayudar a identificar la obesidad, siendo las personas que tengan una circunferencia elevada probablemente las que tengan un IMC igualmente elevado        
- https://scielo.isciii.es/scielo.php?script=sci_arttext&pid=S0212-16112010000900009    
- https://ojs.unemi.edu.ec/index.php/facsalud-unemi/article/view/1463  

```{r}
# Obtenemos los nombres de todas las columnas en el conjunto de datos original
nombres_completos <- names(datos)

# Identificamos las variables restantes
variables_restantes <- setdiff(nombres_completos, nombres_variables)

#por si hay que quitar height y weight igual que en EP09
#variables_restantes <- setdiff(variables_restantes, c("Height", "Weight"))

# Como queremos predecir estas variables, deberiamos quitarlas del conjunto de datos
variables_restantes <- setdiff(variables_restantes, c("EN", "IMC"))


# Creamos un arreglo que tenga las variables restantes del conjunto de datos original
datos_restantes <- datos[, variables_restantes]



variables_restantes
```

## 5.-Usando el entorno R, construir un modelo de regresión logística con el predictor seleccionado en el paso anterior y utilizando de la muestra obtenida.

```{r}
#logit indica que usamos regresion logistica
set.seed(6887)

# Sacamos EN y lo convertimos en factor
muestra_entrenamiento <- muestra_entrenamiento %>%
    mutate(EN = factor(EN, levels = c("no sobrepeso", "sobrepeso")))

#Ajustar modelo.
modelo <- glm(EN ~ Waist.Girth, family = binomial(link = "logit"), data = muestra_entrenamiento)

print(summary (modelo))

#Evaluar el modelo con el conjunto de entrenamiento.
probs_ent <- fitted(modelo)

# Graficar curva ROC, indicando AUC obtenido.
ROC_ent <- roc(muestra_entrenamiento[["EN"]], probs_ent) 
texto_ent<- sprintf("AUC = %.2f", ROC_ent[["auc"]])
g_roc_ent <- ggroc(ROC_ent, color = 2)
g_roc_ent <- g_roc_ent + geom_segment(aes(x = 1, xend = 0, y =
                                            0, yend= 1), linetype = "dashed")

g_roc_ent <- g_roc_ent + annotate("text", x= 0.3, y= 0.3,
                                  label = texto_ent)
g_roc_ent <- g_roc_ent + theme_pubr ()
print(g_roc_ent)

#Obtener las predicciones.
umbral <- 0.5
preds_ent <- sapply(probs_ent,
                    function(p) ifelse(p >= umbral, "sobrepeso", "no sobrepeso")) 
preds_ent <- factor(preds_ent, levels = c("no sobrepeso", "sobrepeso"))

# Obtener y mostrar estadísticas de clasificación en datos de entrenamiento. 
mat_conf_ent <- confusionMatrix(preds_ent, muestra_entrenamiento[["EN"]],
                                positive = "sobrepeso")
cat("\n\nEvaluación del modelo (cjto. de entrenamiento): \n")
cat("-----------------\n")
print(mat_conf_ent[["table"]])
cat ("\n")

cat(sprintf(" Exactitud: %.3f\n", mat_conf_ent [["overall"]]["Accuracy"]))
cat(sprintf(" Sensibilidad: %.3f\n", mat_conf_ent[["byClass"]]["Sensitivity"]))
cat(sprintf("Especificidad: %.3f\n", mat_conf_ent [["byClass"]]["Specificity"]))


# Evaluar el modelo con el conjunto de prueba.
probs_pru <- predict(modelo, muestra_prueba, type="response")

# Lo convertimos en factores para que sea coherente con la muestra anterior
muestra_prueba <- muestra_prueba %>%
    mutate(EN = factor(EN, levels = c("no sobrepeso", "sobrepeso")))

# Graficar curva ROC, indicando AUC obtenido.
ROC_pru<- roc(muestra_prueba[["EN"]], probs_pru)

texto_pru <- sprintf("AUC=  %.2f", ROC_pru[["auc"]]) 
g_roc_pru <- ggroc(ROC_pru, color = 2)
g_roc_pru <- g_roc_pru + geom_segment(aes(x = 1, xend = 0, 
                                          y=0, yend= 1),
                                      linetype ="dashed")

g_roc_pru <- g_roc_pru + annotate("text", x= 0.3, y= 0.3, label =texto_pru) 
g_roc_pru <- g_roc_pru+theme_pubr()
print(g_roc_pru)
# Obtener las predicciones (con el mismo umbral). 
preds_pru <- sapply(probs_pru,
                    function(p) ifelse(p >= umbral, "sobrepeso", "no sobrepeso")) 
preds_pru <- factor(preds_pru, levels = c("no sobrepeso", "sobrepeso"))

# Obtener y mostrar estadísticas de clasificación en datos de prueba. 
mat_conf_pru <- confusionMatrix(preds_pru, muestra_prueba[["EN"]],
                                positive="sobrepeso")
cat("\n\nEvaluación del modelo (cjto. de prueba): \n")
cat ("------------\n")
print(mat_conf_pru [["table"]])
cat("\n")
cat(sprintf(" Exactitud: %.3f\n", mat_conf_pru [["overall"]]["Accuracy"])) 
cat(sprintf(" Sensibilidad: %.3f\n", mat_conf_pru [["byClass"]]["Sensitivity"]))
cat(sprintf("Especificidad: %.3f\n", mat_conf_pru [["byClass"]]["Specificity"]))

# Evaluar la linealidad entre predictor y respuesta transformada
datos_lin <- muestra_entrenamiento %>%
    select(Waist.Girth) %>%
    mutate(Logit = log(fitted(modelo)/(1-fitted(modelo))))

p_lin <- ggscatter(datos_lin, x = "Waist.Girth", y = "Logit",
                   add = "reg.line", add.params = list(color = "blue"))
p_lin <- p_lin + labs(x = "Circunferencia de cintura", 
                      y = "Logit (EN)")
print(p_lin)

# Evaluar independencia de residuos
dwtest <- durbinWatsonTest(modelo)
cat("\nPrueba de independencia de residuos:\n")
print(dwtest)

# Evaluar normalidad de residuos
residuos_estand <- rstandard(modelo)
qqnorm(residuos_estand)
qqline(residuos_estand)

# Identificar casos influyentes
infl <- influence.measures(modelo)
casos_influyentes <- which(apply(infl$is.inf, 1, any))
cat("\nCasos influyentes:\n")
print(rownames(infl$infmat)[casos_influyentes])
```

Se ha creado un modelo de regresión logística con variable dependiente EN y waist girth como variable independiente. 
Con la matriz de confusión con el conjunto de entramiento se han predicho a 38 personas con "no sobrepeso" correctamente, mientras 12 han sido incorrectas. Igualmente se han predicho se han predicho a 38 personas con "sobrepeso" correctamente, mientras 12 han sido incorrectas.

Con la matriz del conjunto de prueba se han predicho a 23 personas con "no sobrepeso" correctamente, mientras 5 han sido incorrectas. Igualmente se han predicho se han predicho a 20 personas con "sobrepeso" correctamente, mientras 2 han sido incorrectas.


## 6.-Usando estas herramientas para la exploración de modelos del entorno R1, buscar entre dos y cinco predictores de entre las variables seleccionadas al azar, recordadas en el punto 3, para agregar al modelo obtenido en el paso 5.

```{r}
# Partimos del modelo base que ya tiene Waist.Girth
modelo_base <- modelo

# Recordamos las 8 variables seleccionadas anteriormente
variables_seleccionadas <- c("Knees.diameter", "Gender", "Chest.Girth", 
                            "Ankle.Minimum.Girth", "Age", 
                            "Navel.Girth", "Hip.Girth", 
                            "Elbows.diameter")

# Evaluación de modelos con dos predictores
cat("Evaluando modelos con dos predictores (Waist.Girth + otro):\n")
cat("------------------------------------------------\n")
for(var in variables_seleccionadas) {
    formula <- paste("EN ~ Waist.Girth +", var)
    modelo_temp <- glm(formula, family = binomial(link = "logit"), 
                      data = muestra_entrenamiento)
    cat("\nModelo con", var, ":\n")
    cat("AIC:", AIC(modelo_temp), "\n")
    cat("Devianza:", modelo_temp$deviance, "\n")
}

# Seleccionamos el mejor modelo de dos predictores
modelo_2pred <- glm(EN ~ Waist.Girth + Hip.Girth, 
                   family = binomial(link = "logit"), 
                   data = muestra_entrenamiento)

# Evaluación de modelos con tres predictores
cat("\nEvaluando modelos con tres predictores:\n")
cat("------------------------------------\n")
for(var in setdiff(variables_seleccionadas, "Hip.Girth")) {
    formula <- paste("EN ~ Waist.Girth + Hip.Girth +", var)
    modelo_temp <- glm(formula, family = binomial(link = "logit"), 
                      data = muestra_entrenamiento)
    cat("\nAgregando", var, ":\n")
    cat("AIC:", AIC(modelo_temp), "\n")
    cat("Devianza:", modelo_temp$deviance, "\n")
}

# Seleccionamos el mejor modelo de tres predictores
modelo_3pred <- glm(EN ~ Waist.Girth + Hip.Girth + Knees.diameter, 
                   family = binomial(link = "logit"), 
                   data = muestra_entrenamiento)

# Evaluación de modelos con cuatro predictores
cat("\nEvaluando modelos con cuatro predictores:\n")
cat("-------------------------------------\n")
variables_restantes <- setdiff(variables_seleccionadas, c("Hip.Girth", "Knees.diameter"))
for(var in variables_restantes) {
    formula <- paste("EN ~ Waist.Girth + Hip.Girth + Knees.diameter +", var)
    modelo_temp <- glm(formula, family = binomial(link = "logit"), 
                      data = muestra_entrenamiento)
    cat("\nAgregando", var, ":\n")
    cat("AIC:", AIC(modelo_temp), "\n")
    cat("Devianza:", modelo_temp$deviance, "\n")
}

# Comparación formal de modelos
cat("\nComparación de modelos:\n")
cat("----------------------\n")
print(anova(modelo_base, modelo_2pred, modelo_3pred, test = "Chisq"))

# Evaluación de multicolinealidad para cada modelo
cat("\nFactores de inflación de varianza - Modelo 2 predictores:\n")
print(vif(modelo_2pred))

cat("\nFactores de inflación de varianza - Modelo 3 predictores:\n")
print(vif(modelo_3pred))

# Resumen del modelo seleccionado
cat("\nResumen del modelo seleccionado:\n")
cat("-----------------------------\n")
print(summary(modelo_3pred))

  
```
#Eleccion del modelo:
```{r}
# Conclusión del análisis de selección de predictores:
#
# 1. Proceso de selección sistemática:
#    - Se evaluaron combinaciones de predictores con las variables seleccionadas
#    - Se analizaron modelos con 2, 3 y 4 predictores partiendo de Waist.Girth
#    - Se utilizó AIC, devianza y significancia estadística como criterios
#
# 2. Resultados del modelo seleccionado:
#    - El modelo incluye Waist.Girth, Hip.Girth y Knees.diameter
#    - Waist.Girth es altamente significativo (p=0.0064)
#    - Knees.diameter es significativo (p=0.0337)
#    - Hip.Girth no resultó significativo (p=0.4625)
#    - AIC = 93.249
#    - Devianza se redujo de 138.629 (nulo) a 85.249
#    - VIF < 2.1 para todos los predictores
#
# 3. Basado en los resultados, recomendamos un modelo más parsimonioso:
modelo_final <- glm(EN ~ Waist.Girth + Knees.diameter, 
                   family = binomial(link = "logit"), 
                   data = muestra_entrenamiento)

print(summary(modelo_final))
```

## 7.-Evaluar la confiabilidad de los modelos (i.e. que tengan un buen nivel de ajuste y son generalizables) y “arreglarlos” en caso de que tengan algún problema.
```{r}

```

## 8.-Usando código estándar1, evaluar el poder predictivo de los modelos con los datos de las 50 personas que no se incluyeron en su construcción en términos de sensibilidad y especificidad.