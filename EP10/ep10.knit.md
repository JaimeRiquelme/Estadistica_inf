---
title: "EP10"
author: "Grupo 8"
date: "2024-12-10"
output: pdf_document
---
Para este ejercicio usaremos los datos de medidas anatómicas recolectados por Heinz et al. (2003) que ya conocimos en el ejercicio práctico anterior (disponibles en el archivo "EP09 Datos.csv"). Como en este case se requiere de una variable dicotómica, vamos a realizar lo siguiente:

1.- El equipo crea la variable IMC (índice de masa corporal) como el peso de una persona (en kilogramos) dividida por el cuadrado de su estatura (en metros).
2.- Si bien esta variable se usa para clasificar a las personas en varias clases de estado nutricional (bajo peso, normal, sobrepeso, obesidad, obesidad mórbida), para efectos de este ejercicio, usaremos dos clases: sobrepeso (IMC ≥ 23,2) y no sobrepeso (IMC < 23,2).
3.- El equipo crea la variable dicotómica EN (estado nutricional) de acuerdo al valor de IMC de cada persona.
Ahora podemos construir un modelo de regresión logística para predecir la variable EN, de acuerdo con las siguientes instrucciones:

## 1.-Definir la semilla a utilizar, que corresponde a los últimos cuatro dígitos del RUN (sin considerar el dígito verificador) del integrante de mayor edad del equipo.


``` r
#Realizamos la lectura de los datos.

datos <- read.csv2("EP09 Datos.csv")

#Definimos la semilla a utilizar

set.seed(6887)
```

## 2.-Seleccionar una muestra de 150 mujeres (si la semilla es un número par) o 150 hombres (si la semilla es impar), asegurando que la mitad tenga estado nutricional “sobrepeso” y la otra mitad “no sobrepeso” en cada caso. Dividir esta muestra en dos conjuntos: los datos de 100 personas (50 con EN “sobrepeso”) para utilizar en la construcción de los modelos (entramiento) y 50 personas (25 con EN “sobrepeso”) para poder evaluarlos.


``` r
# Librerias a utilizar
library(caret) 
```

```
## Loading required package: ggplot2
```

```
## Loading required package: lattice
```

``` r
library(dplyr) 
```

```
## 
## Attaching package: 'dplyr'
```

```
## The following objects are masked from 'package:stats':
## 
##     filter, lag
```

```
## The following objects are masked from 'package:base':
## 
##     intersect, setdiff, setequal, union
```

``` r
library(ggpubr)
library(pROC)
```

```
## Type 'citation("pROC")' for a citation.
```

```
## 
## Attaching package: 'pROC'
```

```
## The following objects are masked from 'package:stats':
## 
##     cov, smooth, var
```

``` r
library(car)  
```

```
## Loading required package: carData
```

```
## 
## Attaching package: 'car'
```

```
## The following object is masked from 'package:dplyr':
## 
##     recode
```

``` r
#Primero creamos la variable IMC para cada persona
#Añadimos la nueva columna IMC a la tabla de datos usando mutate

# Convertimos la altura de centímetros a metros
datos <- datos %>% mutate(Height = Height / 100)

# Calculamos el IMC 
datos <- datos %>% mutate(IMC = Weight / (Height^2))

#Segundo creamos la variable EN para cada persona
datos <- datos %>% mutate(EN = ifelse(IMC >= 23.2, "sobrepeso", "no sobrepeso"))

#Seleccionamos la muestra de 150 hombres.
muestra_sobrepeso <- datos %>% filter(Gender == 1 & EN == "sobrepeso") %>% sample_n(75, replace = FALSE)
muestra_no_sobrepeso <- datos %>% filter(Gender == 1 & EN == "no sobrepeso") %>% sample_n(75, replace = FALSE)

#Seleccionamos 50 personas sobrepeso y 50 personas no sobrepeso para construir los modelos. 

muestra_sobrepeso_modelo <- muestra_sobrepeso[1:50,]
muestra_no_sobrepeso_modelo <- muestra_no_sobrepeso[1:50,]

#Seleccionamos 25 personas sobre peso y 25 personas no sobre peso para evaluar los modelos.

muestra_sobrepeso_evaluar <- muestra_sobrepeso[51:75,]
muestra_no_sobrepeso_evaluar <- muestra_no_sobrepeso[51:75,]

# Combinar los conjuntos de entrenamiento
muestra_entrenamiento <- bind_rows(muestra_sobrepeso_modelo, muestra_no_sobrepeso_modelo)

# Combinar los conjuntos de prueba
muestra_prueba <- bind_rows(muestra_sobrepeso_evaluar, muestra_no_sobrepeso_evaluar)
```

## 3.-Recordar las ocho posibles variables predictoras seleccionadas de forma aleatoria en el ejercicio anterior.

``` r
#Aplicando filtro para obtener solo las 8 variables que obtuvimos aleatoriamente
# Guardar los nombres de las variables seleccionadas
nombres_variables <- c("Knees.diameter", "Gender", "Chest.Girth", 
                       "Ankle.Minimum.Girth", "Age", 
                       "Navel.Girth", "Hip.Girth", 
                       "Elbows.diameter")

# Seleccionar las variables deseadas
variables_seleccionadas <- subset(datos, select = c("Knees.diameter", "Gender", "Chest.Girth", 
                                                      "Ankle.Minimum.Girth", "Age", 
                                                      "Navel.Girth", "Hip.Girth", 
                                                      "Elbows.diameter"))
```

## 4.-Seleccionar, de las otras variables, una que el equipo considere que podría ser útil para predecir la clase EN, justificando bien esta selección (idealmente con literatura).
Siendo EN la variable dicotómica estado nutricional seleccionaremos la variables Waist Girth (que es la circunferencia de la cintura)
para predecir el estado nutricional ya que ayuda a evaluar la distribución de la grasa corporal y puede ayudar a identificar la obesidad, siendo las personas que tengan una circunferencia elevada probablemente las que tengan un IMC igualmente elevado        
- https://scielo.isciii.es/scielo.php?script=sci_arttext&pid=S0212-16112010000900009    
- https://ojs.unemi.edu.ec/index.php/facsalud-unemi/article/view/1463  


``` r
# Obtenemos los nombres de todas las columnas en el conjunto de datos original
nombres_completos <- names(datos)

# Identificamos las variables restantes
variables_restantes <- setdiff(nombres_completos, nombres_variables)

#por si hay que quitar height y weight igual que en EP09
#variables_restantes <- setdiff(variables_restantes, c("Height", "Weight"))

# Como queremos predecir estas variables, deberiamos quitarlas del conjunto de datos
variables_restantes <- setdiff(variables_restantes, c("EN", "IMC"))


# Creamos un arreglo que tenga las variables restantes del conjunto de datos original
datos_restantes <- datos[, variables_restantes]



variables_restantes
```

```
##  [1] "Biacromial.diameter"     "Biiliac.diameter"       
##  [3] "Bitrochanteric.diameter" "Chest.depth"            
##  [5] "Chest.diameter"          "Wrists.diameter"        
##  [7] "Ankles.diameter"         "Shoulder.Girth"         
##  [9] "Waist.Girth"             "Thigh.Girth"            
## [11] "Bicep.Girth"             "Forearm.Girth"          
## [13] "Knee.Girth"              "Calf.Maximum.Girth"     
## [15] "Wrist.Minimum.Girth"     "Weight"                 
## [17] "Height"
```

## 5.-Usando el entorno R, construir un modelo de regresión logística con el predictor seleccionado en el paso anterior y utilizando de la muestra obtenida.


``` r
#logit indica que usamos regresion logistica
set.seed(6887)

# Sacamos EN y lo convertimos en factor
muestra_entrenamiento <- muestra_entrenamiento %>%
    mutate(EN = factor(EN, levels = c("no sobrepeso", "sobrepeso")))

#Ajustar modelo.
modelo <- glm(EN ~ Waist.Girth, family = binomial(link = "logit"), data = muestra_entrenamiento)

print(summary (modelo))
```

```
## 
## Call:
## glm(formula = EN ~ Waist.Girth, family = binomial(link = "logit"), 
##     data = muestra_entrenamiento)
## 
## Coefficients:
##              Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -19.36784    3.93084  -4.927 8.34e-07 ***
## Waist.Girth   0.23649    0.04816   4.911 9.08e-07 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 138.629  on 99  degrees of freedom
## Residual deviance:  94.111  on 98  degrees of freedom
## AIC: 98.111
## 
## Number of Fisher Scoring iterations: 5
```

``` r
#Evaluar el modelo con el conjunto de entrenamiento.
probs_ent <- fitted(modelo)

# Graficar curva ROC, indicando AUC obtenido.
ROC_ent <- roc(muestra_entrenamiento[["EN"]], probs_ent) 
```

```
## Setting levels: control = no sobrepeso, case = sobrepeso
```

```
## Setting direction: controls < cases
```

``` r
texto_ent<- sprintf("AUC = %.2f", ROC_ent[["auc"]])
g_roc_ent <- ggroc(ROC_ent, color = 2)
g_roc_ent <- g_roc_ent + geom_segment(aes(x = 1, xend = 0, y =
                                            0, yend= 1), linetype = "dashed")

g_roc_ent <- g_roc_ent + annotate("text", x= 0.3, y= 0.3,
                                  label = texto_ent)
g_roc_ent <- g_roc_ent + theme_pubr ()
print(g_roc_ent)
```

```
## Warning in geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1), linetype = "dashed"): All aesthetics have length 1, but the data has 81 rows.
## i Please consider using `annotate()` or provide this layer with data containing
##   a single row.
```

![](ep10_files/figure-latex/unnamed-chunk-5-1.pdf)<!-- --> 

``` r
#Obtener las predicciones.
umbral <- 0.5
preds_ent <- sapply(probs_ent,
                    function(p) ifelse(p >= umbral, "sobrepeso", "no sobrepeso")) 
preds_ent <- factor(preds_ent, levels = c("no sobrepeso", "sobrepeso"))

# Obtener y mostrar estadísticas de clasificación en datos de entrenamiento. 
mat_conf_ent <- confusionMatrix(preds_ent, muestra_entrenamiento[["EN"]],
                                positive = "sobrepeso")
cat("\n\nEvaluación del modelo (cjto. de entrenamiento): \n")
```

```
## 
## 
## Evaluación del modelo (cjto. de entrenamiento):
```

``` r
cat("-----------------\n")
```

```
## -----------------
```

``` r
print(mat_conf_ent[["table"]])
```

```
##               Reference
## Prediction     no sobrepeso sobrepeso
##   no sobrepeso           38        12
##   sobrepeso              12        38
```

``` r
cat ("\n")
```

``` r
cat(sprintf(" Exactitud: %.3f\n", mat_conf_ent [["overall"]]["Accuracy"]))
```

```
##  Exactitud: 0.760
```

``` r
cat(sprintf(" Sensibilidad: %.3f\n", mat_conf_ent[["byClass"]]["Sensitivity"]))
```

```
##  Sensibilidad: 0.760
```

``` r
cat(sprintf("Especificidad: %.3f\n", mat_conf_ent [["byClass"]]["Specificity"]))
```

```
## Especificidad: 0.760
```

``` r
# Evaluar el modelo con el conjunto de prueba.
probs_pru <- predict(modelo, muestra_prueba, type="response")

# Lo convertimos en factores para que sea coherente con la muestra anterior
muestra_prueba <- muestra_prueba %>%
    mutate(EN = factor(EN, levels = c("no sobrepeso", "sobrepeso")))

# Graficar curva ROC, indicando AUC obtenido.
ROC_pru<- roc(muestra_prueba[["EN"]], probs_pru)
```

```
## Setting levels: control = no sobrepeso, case = sobrepeso
## Setting direction: controls < cases
```

``` r
texto_pru <- sprintf("AUC=  %.2f", ROC_pru[["auc"]]) 
g_roc_pru <- ggroc(ROC_pru, color = 2)
g_roc_pru <- g_roc_pru + geom_segment(aes(x = 1, xend = 0, 
                                          y=0, yend= 1),
                                      linetype ="dashed")

g_roc_pru <- g_roc_pru + annotate("text", x= 0.3, y= 0.3, label =texto_pru) 
g_roc_pru <- g_roc_pru+theme_pubr()
print(g_roc_pru)
```

```
## Warning in geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1), linetype = "dashed"): All aesthetics have length 1, but the data has 45 rows.
## i Please consider using `annotate()` or provide this layer with data containing
##   a single row.
```

![](ep10_files/figure-latex/unnamed-chunk-5-2.pdf)<!-- --> 

``` r
# Obtener las predicciones (con el mismo umbral). 
preds_pru <- sapply(probs_pru,
                    function(p) ifelse(p >= umbral, "sobrepeso", "no sobrepeso")) 
preds_pru <- factor(preds_pru, levels = c("no sobrepeso", "sobrepeso"))

# Obtener y mostrar estadísticas de clasificación en datos de prueba. 
mat_conf_pru <- confusionMatrix(preds_pru, muestra_prueba[["EN"]],
                                positive="sobrepeso")
cat("\n\nEvaluación del modelo (cjto. de prueba): \n")
```

```
## 
## 
## Evaluación del modelo (cjto. de prueba):
```

``` r
cat ("------------\n")
```

```
## ------------
```

``` r
print(mat_conf_pru [["table"]])
```

```
##               Reference
## Prediction     no sobrepeso sobrepeso
##   no sobrepeso           23         5
##   sobrepeso               2        20
```

``` r
cat("\n")
```

``` r
cat(sprintf(" Exactitud: %.3f\n", mat_conf_pru [["overall"]]["Accuracy"])) 
```

```
##  Exactitud: 0.860
```

``` r
cat(sprintf(" Sensibilidad: %.3f\n", mat_conf_pru [["byClass"]]["Sensitivity"]))
```

```
##  Sensibilidad: 0.800
```

``` r
cat(sprintf("Especificidad: %.3f\n", mat_conf_pru [["byClass"]]["Specificity"]))
```

```
## Especificidad: 0.920
```

``` r
# Evaluar la linealidad entre predictor y respuesta transformada
datos_lin <- muestra_entrenamiento %>%
    select(Waist.Girth) %>%
    mutate(Logit = log(fitted(modelo)/(1-fitted(modelo))))

p_lin <- ggscatter(datos_lin, x = "Waist.Girth", y = "Logit",
                   add = "reg.line", add.params = list(color = "blue"))
p_lin <- p_lin + labs(x = "Circunferencia de cintura", 
                      y = "Logit (EN)")
print(p_lin)
```

![](ep10_files/figure-latex/unnamed-chunk-5-3.pdf)<!-- --> 

``` r
# Evaluar independencia de residuos
dwtest <- durbinWatsonTest(modelo)
cat("\nPrueba de independencia de residuos:\n")
```

```
## 
## Prueba de independencia de residuos:
```

``` r
print(dwtest)
```

```
##  lag Autocorrelation D-W Statistic p-value
##    1       0.7323669     0.5319008       0
##  Alternative hypothesis: rho != 0
```

``` r
# Evaluar normalidad de residuos
residuos_estand <- rstandard(modelo)
qqnorm(residuos_estand)
qqline(residuos_estand)
```

![](ep10_files/figure-latex/unnamed-chunk-5-4.pdf)<!-- --> 

``` r
# Identificar casos influyentes
infl <- influence.measures(modelo)
casos_influyentes <- which(apply(infl$is.inf, 1, any))
cat("\nCasos influyentes:\n")
```

```
## 
## Casos influyentes:
```

``` r
print(rownames(infl$infmat)[casos_influyentes])
```

```
## [1] "77"
```

Se ha creado un modelo de regresión logística con variable dependiente EN y waist girth como variable independiente. 
Con la matriz de confusión con el conjunto de entramiento se han predicho a 38 personas con "no sobrepeso" correctamente, mientras 12 han sido incorrectas. Igualmente se han predicho se han predicho a 38 personas con "sobrepeso" correctamente, mientras 12 han sido incorrectas.

Con la matriz del conjunto de prueba se han predicho a 23 personas con "no sobrepeso" correctamente, mientras 5 han sido incorrectas. Igualmente se han predicho se han predicho a 20 personas con "sobrepeso" correctamente, mientras 2 han sido incorrectas.


## 6.-Usando estas herramientas para la exploración de modelos del entorno R1, buscar entre dos y cinco predictores de entre las variables seleccionadas al azar, recordadas en el punto 3, para agregar al modelo obtenido en el paso 5.


``` r
# Primero veamos qué pasa al agregar cada una de las variables seleccionadas al modelo actual
cat("Single term additions\n")
```

```
## Single term additions
```

``` r
cat("Model: EN ~ Waist.Girth\n")
```

```
## Model: EN ~ Waist.Girth
```

``` r
modelo_base <- modelo  # guardamos el modelo del punto 5

# Crear fórmulas con cada predictor adicional posible
nuevos_predictores <- c("Knees.diameter", "Chest.Girth", 
                       "Ankle.Minimum.Girth", "Age", 
                       "Navel.Girth", "Hip.Girth", 
                       "Elbows.diameter")

# Evaluamos cada predictor
for(predictor in nuevos_predictores) {
    formula_nueva <- as.formula(paste("EN ~ Waist.Girth +", predictor))
    modelo_nuevo <- glm(formula_nueva, family = binomial(link = "logit"), 
                       data = muestra_entrenamiento)
    cat("\nAgregando", predictor, ":\n")
    cat("AIC:", AIC(modelo_nuevo), "\n")
    cat("Deviance:", modelo_nuevo$deviance, "\n")
}
```

```
## 
## Agregando Knees.diameter :
## AIC: 91.80487 
## Deviance: 85.80487 
## 
## Agregando Chest.Girth :
## AIC: 98.03269 
## Deviance: 92.03269 
## 
## Agregando Ankle.Minimum.Girth :
## AIC: 99.26809 
## Deviance: 93.26809 
## 
## Agregando Age :
## AIC: 93.12154 
## Deviance: 87.12154 
## 
## Agregando Navel.Girth :
## AIC: 99.5644 
## Deviance: 93.5644 
## 
## Agregando Hip.Girth :
## AIC: 96.11542 
## Deviance: 90.11542 
## 
## Agregando Elbows.diameter :
## AIC: 98.88846 
## Deviance: 92.88846
```

``` r
# Seleccionamos el mejor predictor adicional (el que da menor AIC)
modelo_2pred <- glm(EN ~ Waist.Girth + Hip.Girth, 
                   family = binomial(link = "logit"), 
                   data = muestra_entrenamiento)

# Comparamos los modelos
cat("\nComparación de modelos:\n")
```

```
## 
## Comparación de modelos:
```

``` r
cat("------------------------\n")
```

```
## ------------------------
```

``` r
print(anova(modelo_base, modelo_2pred, test = "Chisq"))
```

```
## Analysis of Deviance Table
## 
## Model 1: EN ~ Waist.Girth
## Model 2: EN ~ Waist.Girth + Hip.Girth
##   Resid. Df Resid. Dev Df Deviance Pr(>Chi)  
## 1        98     94.111                       
## 2        97     90.115  1   3.9957  0.04562 *
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

``` r
# Evaluamos si podemos agregar un tercer predictor
cat("\nEvaluando tercer predictor:\n")
```

```
## 
## Evaluando tercer predictor:
```

``` r
for(predictor in setdiff(nuevos_predictores, "Hip.Girth")) {
    formula_nueva <- as.formula(paste("EN ~ Waist.Girth + Hip.Girth +", predictor))
    modelo_nuevo <- glm(formula_nueva, family = binomial(link = "logit"), 
                       data = muestra_entrenamiento)
    cat("\nAgregando", predictor, ":\n")
    cat("AIC:", AIC(modelo_nuevo), "\n")
    cat("Deviance:", modelo_nuevo$deviance, "\n")
}
```

```
## 
## Agregando Knees.diameter :
## AIC: 93.24916 
## Deviance: 85.24916 
## 
## Agregando Chest.Girth :
## AIC: 97.08056 
## Deviance: 89.08056 
## 
## Agregando Ankle.Minimum.Girth :
## AIC: 97.92056 
## Deviance: 89.92056 
## 
## Agregando Age :
## AIC: 93.74918 
## Deviance: 85.74918 
## 
## Agregando Navel.Girth :
## AIC: 96.85371 
## Deviance: 88.85371 
## 
## Agregando Elbows.diameter :
## AIC: 97.97015 
## Deviance: 89.97015
```

``` r
# Seleccionamos el modelo con tres predictores
modelo_3pred <- glm(EN ~ Waist.Girth + Hip.Girth + Chest.Girth, 
                   family = binomial(link = "logit"), 
                   data = muestra_entrenamiento)

# Comparar los tres modelos
print(anova(modelo_base, modelo_2pred, modelo_3pred, test = "Chisq"))
```

```
## Analysis of Deviance Table
## 
## Model 1: EN ~ Waist.Girth
## Model 2: EN ~ Waist.Girth + Hip.Girth
## Model 3: EN ~ Waist.Girth + Hip.Girth + Chest.Girth
##   Resid. Df Resid. Dev Df Deviance Pr(>Chi)  
## 1        98     94.111                       
## 2        97     90.115  1   3.9957  0.04562 *
## 3        96     89.081  1   1.0349  0.30902  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

``` r
# Veamos el resumen del modelo final seleccionado
cat("\nResumen del modelo final:\n")
```

```
## 
## Resumen del modelo final:
```

``` r
print(summary(modelo_3pred))
```

```
## 
## Call:
## glm(formula = EN ~ Waist.Girth + Hip.Girth + Chest.Girth, family = binomial(link = "logit"), 
##     data = muestra_entrenamiento)
## 
## Coefficients:
##              Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -30.18200    7.02703  -4.295 1.75e-05 ***
## Waist.Girth   0.12846    0.06441   1.995   0.0461 *  
## Hip.Girth     0.15044    0.09026   1.667   0.0956 .  
## Chest.Girth   0.05297    0.05214   1.016   0.3097    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 138.629  on 99  degrees of freedom
## Residual deviance:  89.081  on 96  degrees of freedom
## AIC: 97.081
## 
## Number of Fisher Scoring iterations: 5
```

``` r
# Verificar multicolinealidad
vif_resultado <- vif(modelo_3pred)
cat("\nFactores de inflación de la varianza:\n")
```

```
## 
## Factores de inflación de la varianza:
```

``` r
print(vif_resultado)
```

```
## Waist.Girth   Hip.Girth Chest.Girth 
##    1.742823    1.635141    1.337934
```

## 7.-Evaluar la confiabilidad de los modelos (i.e. que tengan un buen nivel de ajuste y son generalizables) y “arreglarlos” en caso de que tengan algún problema.


## 8.-Usando código estándar1, evaluar el poder predictivo de los modelos con los datos de las 50 personas que no se incluyeron en su construcción en términos de sensibilidad y especificidad.
