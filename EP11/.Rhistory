#Cargamos las librerías necesarias
library(leaps)
library(caret)
library(pROC)
library(car)
library(dplyr)
library(randomForest)
#Realizamos la lectura de los datos.
datos <- read.csv2("EP09 Datos.csv")
#Realizamos la lectura de los datos.
datos <- read.csv2("EP09 Datos.csv")
#Definimos la semilla a utilizar
set.seed(6887)
# Convertimos la altura de centímetros a metros
datos <- datos %>% mutate(Height = Height / 100)
# Calculamos el IMC
datos <- datos %>% mutate(IMC = Weight / (Height^2))
#Segundo creamos la variable EN para cada persona
datos <- datos %>% mutate(EN = ifelse(IMC >= 23.2, 1, 0)) # 1: Sobrepeso, 0: No sobrepeso
noSobrepeso <- datos %>% filter(EN == 0) %>% sample_n(50)
sobrepeso <- datos %>% filter(EN == 1) %>% sample_n(50)
muestra <- rbind(noSobrepeso, sobrepeso)
#Excluimos las variables IMC y EN
variables <- setdiff(names(datos), c("Weight", "IMC", "EN"))
#Seleccionamos los predictores usando regsubsets
leaps_model <- regsubsets(Weight ~ ., data = datos[, c("Weight", variables)],
nbest = 1, nvmax = 8, method = "exhaustive")
#Análisis detallado de los mejores modelos para cada número de predictores
plot(leaps_model)
#Obtenemos los mejores predictores
summary_leaps <- summary(leaps_model)
mejores_predictores <- names(coef(leaps_model, which.min(summary_leaps$cp))[-1])
#Mostramos análisis detallado de los predictores seleccionados
cat("\nMejores predictores seleccionados:\n")
print(mejores_predictores)
#Construcción del modelo con bootstrapping
control <- trainControl(method = "boot", number = 2999)
modelo_lm <- train(Weight ~ .,
data = datos[, c("Weight", mejores_predictores)],
method = "lm",
trControl = control)
#Análisis detallado del modelo final
cat("\nResumen del modelo final:\n")
print(summary(modelo_lm$finalModel))
#Métricas de evaluación
cat("\nMétricas de evaluación del modelo:\n")
print(modelo_lm$results)
#Importancia relativa de las variables
importancia <- varImp(modelo_lm)
print(importancia)
#Diagnósticos del modelo
par(mfrow=c(2,2))
plot(modelo_lm$finalModel)
# Eliminar las variables no deseadas
datos_rfe <- datos[, !(names(datos) %in% c("Weight", "Height", "EN"))]
# Configurar el control de RFE
control_rfe <- rfeControl(
functions = lmFuncs,
method = "repeatedcv",
repeats = 5,
number = 5,
verbose = FALSE
)
# Ejecutar RFE
set.seed(6887)  # Para reproducibilidad
rfe_result <- rfe(
x = datos_rfe %>% select(-IMC),
y = datos_rfe$IMC,
sizes = 10:20,
rfeControl = control_rfe
)
# Análisis detallado de resultados
cat("\nResumen del proceso RFE:\n")
print(rfe_result)
# Visualizar la importancia de las variables
plot(rfe_result, type = c("g", "o"))
# Variables seleccionadas
mejores_variables <- predictors(rfe_result)
cat("\nVariables seleccionadas por RFE:\n")
print(mejores_variables)
# Construir y evaluar el modelo final
modelo_final <- train(
formula(paste("IMC ~", paste(mejores_variables, collapse = " + "))),
data = datos_rfe,
method = "lm",
trControl = trainControl(
method = "repeatedcv",
number = 5,
repeats = 5
)
)
# Resumen detallado del modelo
cat("\nResumen del modelo final:\n")
print(summary(modelo_final$finalModel))
# Métricas de rendimiento
cat("\nMétricas de rendimiento del modelo:\n")
print(modelo_final$results)
# Importancia de las variables en el modelo final
importancia_final <- varImp(modelo_final)
cat("\nImportancia relativa de las variables:\n")
print(importancia_final)
# Diagnósticos visuales
par(mfrow=c(2,2))
plot(modelo_final$finalModel)
# Predicciones vs valores reales
predicciones <- predict(modelo_final, datos_rfe)
plot(datos_rfe$IMC, predicciones,
main = "Valores reales vs predicciones",
xlab = "IMC real",
ylab = "IMC predicho")
abline(0, 1, col = "red")
# Análisis de residuos
residuos <- predicciones - datos_rfe$IMC
hist(residuos,
main = "Distribución de residuos",
xlab = "Residuos",
breaks = 30)
# Eliminar las variables no deseadas
datos_rfe <- datos[, !(names(datos) %in% c("Weight", "Height", "EN"))]
# Configurar el control de RFE
control_rfe <- rfeControl(
functions = lmFuncs,
method = "repeatedcv",
repeats = 5,
number = 5,
verbose = FALSE
)
# Ejecutar RFE
set.seed(6887)  # Para reproducibilidad
rfe_result <- rfe(
x = datos_rfe %>% select(-IMC),
y = datos_rfe$IMC,
sizes = 10:20,
rfeControl = control_rfe
)
# Análisis detallado de resultados
cat("\nResumen del proceso RFE:\n")
print(rfe_result)
# Visualizar la importancia de las variables
plot(rfe_result, type = c("g", "o"))
# Variables seleccionadas
mejores_variables <- predictors(rfe_result)
cat("\nVariables seleccionadas por RFE:\n")
print(mejores_variables)
# Construir y evaluar el modelo final
modelo_final <- train(
formula(paste("IMC ~", paste(mejores_variables, collapse = " + "))),
data = datos_rfe,
method = "lm",
trControl = trainControl(
method = "repeatedcv",
number = 5,
repeats = 5
)
)
# Resumen detallado del modelo
cat("\nResumen del modelo final:\n")
print(summary(modelo_final$finalModel))
# Métricas de rendimiento
cat("\nMétricas de rendimiento del modelo:\n")
print(modelo_final$results)
# Importancia de las variables en el modelo final
importancia_final <- varImp(modelo_final)
cat("\nImportancia relativa de las variables:\n")
print(importancia_final)
# Diagnósticos visuales
par(mfrow=c(2,2))
plot(modelo_final$finalModel)
# Predicciones vs valores reales
predicciones <- predict(modelo_final, datos_rfe)
plot(datos_rfe$IMC, predicciones,
main = "Valores reales vs predicciones",
xlab = "IMC real",
ylab = "IMC predicho")
abline(0, 1, col = "red")
# Análisis de residuos
residuos <- predicciones - datos_rfe$IMC
hist(residuos,
main = "Distribución de residuos",
xlab = "Residuos",
breaks = 30)
# Definimos la semilla a utilizar
set.seed(6887)
# Excluimos las variables IMC, Weight, Height y EN
variables_5 <- setdiff(names(datos), c("Weight", "IMC", "Height", "EN"))
# Seleccionamos las columnas necesarias del data frame
datos_seleccionados <- datos %>% select(all_of(variables_5), EN)
# Convertir EN a factor con nombres de niveles válidos
datos_seleccionados$EN <- factor(datos_seleccionados$EN,
levels = c(0, 1),
labels = c("NoSobrepeso", "Sobrepeso"))
# Configuración del control de RFE
ctrl <- rfeControl(
functions = lrFuncs,  # Usar funciones para regresión logística
method = "LOOCV",
number = nrow(datos_seleccionados)
)
# Realizar RFE
results <- rfe(
x = datos_seleccionados[, -which(names(datos_seleccionados) == "EN")],
y = datos_seleccionados$EN,
sizes = c(2:6),
rfeControl = ctrl,
method = "glm",
family = "binomial",
metric = "Accuracy"  # Cambiamos a Accuracy ya que ROC necesita configuración adicional
)
# Mostrar resultados
print(results)
# Mejor conjunto de predictores obtenidos
predictors <- predictors(results)
print(predictors)
# Construir el modelo final con los mejores predictores
selected_data <- datos_seleccionados[, c(predictors, "EN")]
# Configurar el control para validación cruzada
train_ctrl <- trainControl(
method = "LOOCV",
classProbs = TRUE,
summaryFunction = twoClassSummary,
savePredictions = TRUE
)
# Entrenar el modelo final
final_model <- train(
EN ~ .,
data = selected_data,
method = "glm",
family = binomial,
trControl = train_ctrl,
metric = "ROC"
)
# Generar predicciones
pred_probs <- predict(final_model, selected_data, type = "prob")
# Crear y graficar la curva ROC
roc_curve <- roc(response = selected_data$EN,
predictor = pred_probs[,"Sobrepeso"],
levels = c("NoSobrepeso", "Sobrepeso"))
# Graficar la curva ROC con detalles
plot(roc_curve,
main = "Curva ROC del Modelo de Predicción",
col = "blue",
lwd = 2,
legacy.axes = TRUE)
grid()
abline(a = 0, b = 1, lty = 2, col = "gray")
# Calcular y añadir el AUC al gráfico
auc_value <- auc(roc_curve)
legend("bottomright",
legend = sprintf("AUC = %.3f", auc_value),
col = "blue",
lwd = 2)
# Imprimir resultados detallados
cat("\nResultados del Modelo:\n")
cat("------------------------\n")
cat("AUC:", round(auc_value, 3), "\n")
cat("Predictores seleccionados:", paste(predictors, collapse = ", "), "\n")
# Mostrar matriz de confusión
pred_class <- predict(final_model, selected_data)
conf_matrix <- confusionMatrix(pred_class, selected_data$EN)
print("\nMatriz de Confusión:")
print(conf_matrix)
#Cargamos las librerías necesarias
library(leaps)
library(caret)
library(pROC)
library(car)
library(dplyr)
library(randomForest)
#Realizamos la lectura de los datos.
datos <- read.csv2("EP09 Datos.csv")
#Realizamos la lectura de los datos.
datos <- read.csv2("EP09 Datos.csv")
#Definimos la semilla a utilizar
set.seed(6887)
# Convertimos la altura de centímetros a metros
datos <- datos %>% mutate(Height = Height / 100)
# Calculamos el IMC
datos <- datos %>% mutate(IMC = Weight / (Height^2))
#Segundo creamos la variable EN para cada persona
datos <- datos %>% mutate(EN = ifelse(IMC >= 23.2, 1, 0)) # 1: Sobrepeso, 0: No sobrepeso
noSobrepeso <- datos %>% filter(EN == 0) %>% sample_n(50)
sobrepeso <- datos %>% filter(EN == 1) %>% sample_n(50)
muestra <- rbind(noSobrepeso, sobrepeso)
#Excluimos las variables IMC y EN
variables <- setdiff(names(datos), c("Weight", "IMC", "EN"))
#Seleccionamos los predictores usando regsubsets
leaps_model <- regsubsets(Weight ~ ., data = datos[, c("Weight", variables)],
nbest = 1, nvmax = 8, method = "exhaustive")
#Análisis detallado de los mejores modelos para cada número de predictores
plot(leaps_model)
#Obtenemos los mejores predictores
summary_leaps <- summary(leaps_model)
mejores_predictores <- names(coef(leaps_model, which.min(summary_leaps$cp))[-1])
#Mostramos análisis detallado de los predictores seleccionados
cat("\nMejores predictores seleccionados:\n")
print(mejores_predictores)
#Construcción del modelo con bootstrapping
control <- trainControl(method = "boot", number = 2999)
modelo_lm <- train(Weight ~ .,
data = datos[, c("Weight", mejores_predictores)],
method = "lm",
trControl = control)
#Análisis detallado del modelo final
cat("\nResumen del modelo final:\n")
print(summary(modelo_lm$finalModel))
#Métricas de evaluación
cat("\nMétricas de evaluación del modelo:\n")
print(modelo_lm$results)
#Importancia relativa de las variables
importancia <- varImp(modelo_lm)
print(importancia)
#Diagnósticos del modelo
par(mfrow=c(2,2))
plot(modelo_lm$finalModel)
# Eliminar las variables no deseadas
datos_rfe <- datos[, !(names(datos) %in% c("Weight", "Height", "EN"))]
# Configurar el control de RFE
control_rfe <- rfeControl(
functions = lmFuncs,
method = "repeatedcv",
repeats = 5,
number = 5,
verbose = FALSE
)
# Ejecutar RFE
set.seed(6887)  # Para reproducibilidad
rfe_result <- rfe(
x = datos_rfe %>% select(-IMC),
y = datos_rfe$IMC,
sizes = 10:20,
rfeControl = control_rfe
)
# Análisis detallado de resultados
cat("\nResumen del proceso RFE:\n")
print(rfe_result)
# Visualizar la importancia de las variables
plot(rfe_result, type = c("g", "o"))
# Variables seleccionadas
mejores_variables <- predictors(rfe_result)
cat("\nVariables seleccionadas por RFE:\n")
print(mejores_variables)
# Construir y evaluar el modelo final
modelo_final <- train(
formula(paste("IMC ~", paste(mejores_variables, collapse = " + "))),
data = datos_rfe,
method = "lm",
trControl = trainControl(
method = "repeatedcv",
number = 5,
repeats = 5
)
)
# Resumen detallado del modelo
cat("\nResumen del modelo final:\n")
print(summary(modelo_final$finalModel))
# Métricas de rendimiento
cat("\nMétricas de rendimiento del modelo:\n")
print(modelo_final$results)
# Importancia de las variables en el modelo final
importancia_final <- varImp(modelo_final)
cat("\nImportancia relativa de las variables:\n")
print(importancia_final)
# Diagnósticos visuales
par(mfrow=c(2,2))
plot(modelo_final$finalModel)
# Predicciones vs valores reales
predicciones <- predict(modelo_final, datos_rfe)
plot(datos_rfe$IMC, predicciones,
main = "Valores reales vs predicciones",
xlab = "IMC real",
ylab = "IMC predicho")
abline(0, 1, col = "red")
# Análisis de residuos
residuos <- predicciones - datos_rfe$IMC
hist(residuos,
main = "Distribución de residuos",
xlab = "Residuos",
breaks = 30)
# Definimos la semilla a utilizar
set.seed(6887)
# Excluimos las variables IMC, Weight, Height y EN
variables_5 <- setdiff(names(datos), c("Weight", "IMC", "Height", "EN"))
# Seleccionamos las columnas necesarias del data frame
datos_seleccionados <- datos %>% select(all_of(variables_5), EN)
# Convertir EN a factor con nombres de niveles válidos
datos_seleccionados$EN <- factor(datos_seleccionados$EN,
levels = c(0, 1),
labels = c("NoSobrepeso", "Sobrepeso"))
# Configuración del control de RFE
ctrl <- rfeControl(
functions = lrFuncs,  # Usar funciones para regresión logística
method = "LOOCV",
number = nrow(datos_seleccionados)
)
# Realizar RFE
results <- rfe(
x = datos_seleccionados[, -which(names(datos_seleccionados) == "EN")],
y = datos_seleccionados$EN,
sizes = c(2:6),
rfeControl = ctrl,
method = "glm",
family = "binomial",
metric = "Accuracy"
)
# Mostrar resultados
print(results)
# Mejor conjunto de predictores obtenidos
predictors <- predictors(results)
print(predictors)
# Construir el modelo final con los mejores predictores
selected_data <- datos_seleccionados[, c(predictors, "EN")]
# Configurar el control para validación cruzada
train_ctrl <- trainControl(
method = "LOOCV",
classProbs = TRUE,
summaryFunction = twoClassSummary,
savePredictions = TRUE
)
# Entrenar el modelo final
final_model <- train(
EN ~ .,
data = selected_data,
method = "glm",
family = binomial,
trControl = train_ctrl,
metric = "ROC"
)
# Generar predicciones
pred_probs <- predict(final_model, selected_data, type = "prob")
# Crear y graficar la curva ROC
roc_curve <- roc(response = selected_data$EN,
predictor = pred_probs[,"Sobrepeso"],
levels = c("NoSobrepeso", "Sobrepeso"))
# Graficar la curva ROC con detalles
plot(roc_curve,
main = "Curva ROC del Modelo de Predicción",
col = "blue",
lwd = 2,
legacy.axes = TRUE)
grid()
abline(a = 0, b = 1, lty = 2, col = "gray")
# Calcular y añadir el AUC al gráfico
auc_value <- auc(roc_curve)
legend("bottomright",
legend = sprintf("AUC = %.3f", auc_value),
col = "blue",
lwd = 2)
# Imprimir resultados detallados
cat("\nResultados del Modelo:\n")
cat("------------------------\n")
cat("AUC:", round(auc_value, 3), "\n")
cat("Predictores seleccionados:", paste(predictors, collapse = ", "), "\n")
# Mostrar matriz de confusión
pred_class <- predict(final_model, selected_data)
conf_matrix <- confusionMatrix(pred_class, selected_data$EN)
print("\nMatriz de Confusión:")
print(conf_matrix)
